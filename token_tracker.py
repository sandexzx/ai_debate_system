"""
–°–∏—Å—Ç–µ–º–∞ –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –¥–ª—è –¥–µ–±–∞—Ç–æ–≤.
–ü–æ–º–æ–≥–∞–µ—Ç –ø–æ–Ω–∏–º–∞—Ç—å —ç–∫–æ–Ω–æ–º–∏–∫—É —Å–∏—Å—Ç–µ–º—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞—Ç—Ä–∞—Ç—ã.
"""

import tiktoken
from dataclasses import dataclass, field
from typing import Dict, List, Optional
from datetime import datetime
import json

@dataclass
class TokenUsage:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""
    model_name: str
    role: str  # gatekeeper, debater_pro, judge, etc.
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int
    estimated_cost: float
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class SessionTokenStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≤—Å–µ–π —Å–µ—Å—Å–∏–∏ –¥–µ–±–∞—Ç–æ–≤"""
    session_id: str
    total_requests: int = 0
    total_prompt_tokens: int = 0
    total_completion_tokens: int = 0
    total_tokens: int = 0
    total_cost: float = 0.0
    usage_by_role: Dict[str, List[TokenUsage]] = field(default_factory=dict)
    start_time: datetime = field(default_factory=datetime.now)
    end_time: Optional[datetime] = None

class TokenTracker:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ OpenRouter —Å –∏—Ö pricing.
    """
    
    def __init__(self):
        # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Ü–µ–Ω—ã OpenRouter (–º–æ–∂–µ—Ç –º–µ–Ω—è—Ç—å—Å—è, –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ)
        # –¶–µ–Ω—ã —É–∫–∞–∑–∞–Ω—ã –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤ –≤ USD
        self.pricing = {
            "google/gemini-2.5-flash": {
                "input": 0.0003,   # $0.30 per 1M input tokens -> $0.0003 per 1K input tokens
                "output": 0.0025     # $2.50 per 1M output tokens -> $0.0025 per 1K output tokens
            },
            "anthropic/claude-sonnet-4": {
                "input": 0.003,   # $3 per 1M input tokens -> $0.003 per 1K input tokens
                "output": 0.015     # $15 per 1M output tokens -> $0.015 per 1K output tokens
            },
            "openai/gpt-4o-mini-2024-07-18": {
                "input": 0.00015,  # $0.15 per 1M input tokens -> $0.00015 per 1K input tokens
                "output": 0.00060   # $0.60 per 1M output tokens -> $0.00060 per 1K output tokens
            },
            "google/gemini-2.5-pro": {
                "input": 0.00125,  # $1.25 per 1M input tokens -> $0.00125 per 1K input tokens
                "output": 0.010     # $10 per 1M output tokens -> $0.010 per 1K output tokens
            },
            "openai/o3": {
                "input": 0.002,    # $2 per 1M input tokens -> $0.002 per 1K input tokens
                "output": 0.008      # $8 per 1M output tokens -> $0.008 per 1K output tokens
            },
            "openai/gpt-4.1": {
                "input": 0.002,    # $2 per 1M input tokens -> $0.002 per 1K input tokens
                "output": 0.008      # $8 per 1M output tokens -> $0.008 per 1K output tokens
            }
        }
        
        # –î–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º tiktoken (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
        try:
            self.encoder = tiktoken.get_encoding("cl100k_base")  # GPT-4 encoding
        except:
            self.encoder = None
        
        # –ê–∫—Ç–∏–≤–Ω—ã–µ —Å–µ—Å—Å–∏–∏
        self.sessions: Dict[str, SessionTokenStats] = {}
    
    def estimate_tokens(self, text: str) -> int:
        """
        –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ.
        
        –î–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–¥—Å—á–µ—Ç–∞ –Ω—É–∂–Ω—ã —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ —ç–Ω–∫–æ–¥–µ—Ä—ã,
        –Ω–æ —ç—Ç–æ –¥–∞–µ—Ç —Ö–æ—Ä–æ—à—É—é –æ—Ü–µ–Ω–∫—É –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞—Ç—Ä–∞—Ç.
        """
        if self.encoder:
            return len(self.encoder.encode(text))
        else:
            # Fallback: –ø—Ä–∏–º–µ—Ä–Ω–æ 4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω –¥–ª—è –µ–≤—Ä–æ–ø–µ–π—Å–∫–∏—Ö —è–∑—ã–∫–æ–≤
            return len(text) // 4
    
    def calculate_cost(self, model_id: str, prompt_tokens: int, completion_tokens: int) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤"""
        
        if model_id not in self.pricing:
            # –ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ –Ω–µ—Ç –≤ pricing, –∏—Å–ø–æ–ª—å–∑—É–µ–º gemini-2.5-flash –∫–∞–∫ default
            model_id = "google/gemini-2.5-flash"
        
        pricing = self.pricing[model_id]
        
        input_cost = (prompt_tokens / 1000) * pricing["input"]
        output_cost = (completion_tokens / 1000) * pricing["output"]
        
        return input_cost + output_cost
    
    def start_session(self, session_id: str) -> SessionTokenStats:
        """–ù–∞—á–∏–Ω–∞–µ—Ç –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è"""
        session = SessionTokenStats(session_id=session_id)
        self.sessions[session_id] = session
        return session
    
    def log_request(self, session_id: str, model_id: str, role: str, 
                   prompt_text: str, completion_text: str) -> TokenUsage:
        """
        –õ–æ–≥–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–µ–±–∞—Ç–æ–≤
            model_id: ID –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "google/gemini-2.5-flash")
            role: –†–æ–ª—å –∞–≥–µ–Ω—Ç–∞ (gatekeeper, debater_pro, judge, etc.)
            prompt_text: –¢–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞
            completion_text: –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
        """
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã
        prompt_tokens = self.estimate_tokens(prompt_text)
        completion_tokens = self.estimate_tokens(completion_text)
        total_tokens = prompt_tokens + completion_tokens
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å
        cost = self.calculate_cost(model_id, prompt_tokens, completion_tokens)
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
        usage = TokenUsage(
            model_name=model_id,
            role=role,
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            total_tokens=total_tokens,
            estimated_cost=cost
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–µ—Å—Å–∏–∏
        if session_id not in self.sessions:
            self.start_session(session_id)
        
        session = self.sessions[session_id]
        session.total_requests += 1
        session.total_prompt_tokens += prompt_tokens
        session.total_completion_tokens += completion_tokens
        session.total_tokens += total_tokens
        session.total_cost += cost
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ä–æ–ª—è–º
        if role not in session.usage_by_role:
            session.usage_by_role[role] = []
        session.usage_by_role[role].append(usage)
        
        return usage
    
    def finish_session(self, session_id: str):
        """–ó–∞–≤–µ—Ä—à–∞–µ—Ç —Å–µ—Å—Å–∏—é –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è"""
        if session_id in self.sessions:
            self.sessions[session_id].end_time = datetime.now()
    
    def get_session_stats(self, session_id: str) -> Optional[SessionTokenStats]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å–µ—Å—Å–∏–∏"""
        return self.sessions.get(session_id)
    
    def format_session_report(self, session_id: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∫—Ä–∞—Å–∏–≤—ã–π –æ—Ç—á–µ—Ç –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å–µ—Å—Å–∏–∏"""
        
        session = self.get_session_stats(session_id)
        if not session:
            return f"‚ùå –°–µ—Å—Å–∏—è {session_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        
        # –í—ã—á–∏—Å–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        duration = ""
        if session.end_time:
            delta = session.end_time - session.start_time
            duration = f"{delta.total_seconds():.1f}s"
        else:
            duration = "–≤ –ø—Ä–æ—Ü–µ—Å—Å–µ"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        report_parts = [
            f"üí∞ –û–¢–ß–ï–¢ –ü–û –¢–û–ö–ï–ù–ê–ú –ò –ó–ê–¢–†–ê–¢–ê–ú",
            f"üìä –°–µ—Å—Å–∏—è: {session_id}",
            f"‚è±Ô∏è –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration}",
            f"",
            f"üìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:",
            f"‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {session.total_requests}",
            f"‚Ä¢ –í—Ö–æ–¥—è—â–∏–µ —Ç–æ–∫–µ–Ω—ã: {session.total_prompt_tokens:,}",
            f"‚Ä¢ –ò—Å—Ö–æ–¥—è—â–∏–µ —Ç–æ–∫–µ–Ω—ã: {session.total_completion_tokens:,}",
            f"‚Ä¢ –û–±—â–∏–π –æ–±—ä–µ–º: {session.total_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤",
            f"‚Ä¢ –û—Ü–µ–Ω–æ—á–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${session.total_cost:.4f}",
            f""
        ]
        
        # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ä–æ–ª—è–º
        if session.usage_by_role:
            report_parts.append("üé≠ –†–ê–ó–ë–ò–í–ö–ê –ü–û –†–û–õ–Ø–ú:")
            
            role_names = {
                "gatekeeper": "üö™ –®–≤–µ–π—Ü–∞—Ä",
                "debater_pro": "‚úÖ –°—Ç–æ—Ä–æ–Ω–Ω–∏–∫", 
                "debater_contra": "‚ùå –ü—Ä–æ—Ç–∏–≤–Ω–∏–∫",
                "debater_alternative": "üîÑ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—â–∏–∫",
                "judge": "‚öñÔ∏è –°—É–¥—å—è"
            }
            
            for role, usages in session.usage_by_role.items():
                role_name = role_names.get(role, role)
                total_tokens = sum(u.total_tokens for u in usages)
                total_cost = sum(u.estimated_cost for u in usages)
                
                report_parts.append(f"‚Ä¢ {role_name}: {len(usages)} –∑–∞–ø—Ä–æ—Å–æ–≤, "
                                  f"{total_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤, ${total_cost:.4f}")
        
        # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        if session.total_tokens > 0:
            cost_per_1k_tokens = (session.total_cost / session.total_tokens) * 1000
            report_parts.extend([
                f"",
                f"üí° –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–¨:",
                f"‚Ä¢ –°—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤: ${cost_per_1k_tokens:.4f}",
                f"‚Ä¢ –¢–æ–∫–µ–Ω–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É: {session.total_tokens / max(1, delta.total_seconds() if session.end_time else 1):.1f}" if session.end_time else ""
            ])
        
        return "\n".join(report_parts)
    
    def export_session_usage(self, session_id: str, filename: str = None) -> str:
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ JSON"""
        
        session = self.get_session_stats(session_id)
        if not session:
            return f"‚ùå –°–µ—Å—Å–∏—è {session_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        
        if not filename:
            filename = f"token_usage_{session_id}.json"
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        export_data = {
            "session_id": session.session_id,
            "summary": {
                "total_requests": session.total_requests,
                "total_prompt_tokens": session.total_prompt_tokens,
                "total_completion_tokens": session.total_completion_tokens,
                "total_tokens": session.total_tokens,
                "total_cost": session.total_cost,
                "start_time": str(session.start_time),
                "end_time": str(session.end_time) if session.end_time else None
            },
            "detailed_usage": {}
        }
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∫–∞–∂–¥–æ–π —Ä–æ–ª–∏
        for role, usages in session.usage_by_role.items():
            export_data["detailed_usage"][role] = [
                {
                    "model_name": u.model_name,
                    "prompt_tokens": u.prompt_tokens,
                    "completion_tokens": u.completion_tokens,
                    "total_tokens": u.total_tokens,
                    "estimated_cost": u.estimated_cost,
                    "timestamp": str(u.timestamp)
                }
                for u in usages
            ]
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
            return f"üìÅ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤: {filename}"
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}"

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Å–∏—Å—Ç–µ–º–µ
token_tracker = TokenTracker()
